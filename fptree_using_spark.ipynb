{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------- CONFIGURATION DETAIL ---------------------\n",
      "\n",
      "\n",
      "\tDataset=/tmp/FPTree_Using_Spark/data/items.csv\n",
      "\tsupport=0.5\n",
      "\tconfidence=0.8\n",
      "\titemcount=8\n",
      "\tnumtrans=8\n",
      "\n",
      "----------------------------- FREQUENCY OF ITEM -------------\n",
      "\n",
      "\n",
      "+------------------+----+-------+\n",
      "|items             |freq|support|\n",
      "+------------------+----+-------+\n",
      "|[water]           |5   |0.625  |\n",
      "|[water, fig]      |4   |0.5    |\n",
      "|[water, fig, pear]|4   |0.5    |\n",
      "|[water, pear]     |5   |0.625  |\n",
      "|[banana]          |4   |0.5    |\n",
      "|[pear]            |7   |0.875  |\n",
      "|[fig]             |6   |0.75   |\n",
      "|[fig, pear]       |5   |0.625  |\n",
      "|[orange]          |4   |0.5    |\n",
      "+------------------+----+-------+\n",
      "\n",
      "\n",
      "----------------------------- ASSOCIATION RULES AND CONFIDENCE -------------\n",
      "\n",
      "\n",
      "+-------------+----------+------------------+\n",
      "|antecedent   |consequent|confidence        |\n",
      "+-------------+----------+------------------+\n",
      "|[fig]        |[pear]    |0.8333333333333334|\n",
      "|[fig, pear]  |[water]   |0.8               |\n",
      "|[water, pear]|[fig]     |0.8               |\n",
      "|[water, fig] |[pear]    |1.0               |\n",
      "|[water]      |[fig]     |0.8               |\n",
      "|[water]      |[pear]    |1.0               |\n",
      "+-------------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql import SparkSession\n",
    "from optparse import OptionParser\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def executeFPTree(sc, in_file, min_confidence, min_support):\n",
    "    try:\n",
    "        items = sc.textFile(in_file).map(lambda x : [ item.strip() for item in x.split(',')])\n",
    "        trans = items.count()\n",
    "        itemsset = items.flatMap(lambda x: x)\n",
    "        itemcount = itemsset.distinct().count()\n",
    "        table=items.zipWithIndex().map(lambda x : [x[1], x[0]])\n",
    "                                   \n",
    "        df = table.toDF([\"id\", \"items\"])\n",
    "   \n",
    "        fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=min_support, minConfidence=min_confidence)\n",
    "        model = fpGrowth.fit(df)\n",
    "\n",
    "        print('\\n--------------------- CONFIGURATION DETAIL ---------------------\\n\\n')\n",
    "        \n",
    "        print('\\tDataset=%s'%(in_file))\n",
    "        print('\\tsupport=%s'%(min_support))\n",
    "        print('\\tconfidence=%s'%(min_confidence))\n",
    "        print('\\titemcount=%s'%(itemcount))\n",
    "        print('\\tnumtrans=%s'%(trans))\n",
    "\n",
    "        print('\\n----------------------------- FREQUENCY OF ITEM -------------\\n\\n')\n",
    "        \n",
    "        # Frequent itemsets.\n",
    "        df = model.freqItemsets\n",
    "        supUdf = udf(lambda x:  '%s'%(x/trans), StringType()) \n",
    "        df = df.withColumn('support', supUdf(\"freq\"))\n",
    "        df.show(model.freqItemsets.count(), False)\n",
    "        \n",
    "        df = model.associationRules.drop('lift')\n",
    "        print('\\n----------------------------- ASSOCIATION RULES AND CONFIDENCE -------------\\n\\n')\n",
    "        # Association rules.\n",
    "        df.show(model.associationRules.count(), False)\n",
    "\n",
    "    except:\n",
    "        print('Error in FP Tree')\n",
    "        traceback.print_exc()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    masterNode = 'spark://192.168.56.50:7077'\n",
    "    fileName = '/tmp/FPTree_Using_Spark/data/items.csv'\n",
    "    min_support=0.5\n",
    "    min_confidence=0.8\n",
    "\n",
    "    conf = SparkConf().setAppName(\"FPTee\").setMaster(masterNode)\n",
    "    ss = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "    ss.sparkContext.setLogLevel(\"ERROR\")\n",
    "    sc = ss.sparkContext\n",
    "    executeFPTree(sc, fileName, min_confidence, min_support)\n",
    "    ss.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
